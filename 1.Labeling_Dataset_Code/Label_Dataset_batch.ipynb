{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True #不生成pychache文件，要放在导入模块前才生效\n",
    "\n",
    "import os\n",
    "import scipy.signal as signal\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "fs = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretraining a control filter with 20Hz-7980Hz and divide it into 15 sub filters\n",
    "\n",
    "%run Pretraining_sub_control_filters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2853e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthesized noise dataset: 80000 random noises\n",
    "\n",
    "from DataSet_construction import Generating_Synthetic_NoiseDataset\n",
    "\n",
    "Folder_name_list_of_data_set =['Dataset/Synthesized_Dataset/Training_data', 'Dataset/Synthesized_Dataset/Validate_data', 'Dataset/Synthesized_Dataset/Testing_data']\n",
    "N_sample_list =[80000, 2000, 2000]\n",
    "for Folder_name_of_data_set, N_sample in zip(Folder_name_list_of_data_set,N_sample_list):\n",
    "    if not os.path.exists(Folder_name_of_data_set):\n",
    "        Generating_Synthetic_NoiseDataset(N_sample=N_sample, Folder_name=Folder_name_of_data_set)\n",
    "    else:\n",
    "        print(Folder_name_of_data_set + 'exists !!!')\n",
    "        \n",
    "# generated 80000 training data, 2000 Validate data, 2000 test data. Each folder has a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by batch (batch=1000, step_size=0.001, SNR=30)\n",
    "# Hard Label noise dataset using the 15 pre-trained sub filters\n",
    "from Automatic_Hard_Label_Subfilters_batch import Automatic_label\n",
    "\n",
    "path_mat = 'models/Pretrained_Sub_Control_filters.mat'\n",
    "\n",
    "Labeler = Automatic_label(sufix='.wav', folder_path='Dataset/Synthesized_Dataset/Training_data', path_mat=path_mat, Index_file='Hard_Index.csv', threshold=0.5)\n",
    "Labeler.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f280d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# by batch (batch=1000, step_size=0.001, SNR=30)\n",
    "# Soft Label noise dataset using the 15 pre-trained sub filters\n",
    "from Automatic_Soft_Label_Subfilters_batch import Automatic_label\n",
    "\n",
    "path_mat = 'models/Pretrained_Sub_Control_filters.mat'\n",
    "\n",
    "Labeler = Automatic_label(sufix='.wav', folder_path='Dataset/Synthesized_Dataset/Training_data', path_mat=path_mat, Index_file='Soft_Index.csv')\n",
    "Labeler.label()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
